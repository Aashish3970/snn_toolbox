Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/parsing/utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/parsing/utils.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/parsing/utils.py	(date 1583363499453)
@@ -34,7 +34,7 @@
 
 from abc import abstractmethod
 
-import keras
+import tensorflow.keras as keras
 import numpy as np
 
 
@@ -1014,6 +1014,8 @@
         inbound_layers = layer._inbound_nodes[0].inbound_layers
     except AttributeError:  # For Keras backward-compatibility.
         inbound_layers = layer.inbound_nodes[0].inbound_layers
+    if not isinstance(inbound_layers, (list, tuple)):
+        inbound_layers = [inbound_layers]
     return inbound_layers
 
 
@@ -1130,7 +1132,12 @@
     fanout = 0
     for next_layer in next_layers:
         if 'Conv' in next_layer.name and not has_stride_unity(next_layer):
-            fanout = np.zeros(layer.output_shape[1:])
+            shape = layer.output_shape
+            if 'input' in layer.name:
+                from snntoolbox.parsing.model_libs.keras_input_lib import \
+                    fix_input_layer_shape
+                shape = fix_input_layer_shape(shape)
+            fanout = np.zeros(shape[1:])
             break
 
     for next_layer in next_layers:
@@ -1176,7 +1183,12 @@
     sx = layer_post.strides[1]
     sy = layer_post.strides[0]
 
-    fanout = np.zeros(layer_pre.output_shape[1:])
+    shape = layer_pre.output_shape
+    if 'input' in layer_pre.name:
+        from snntoolbox.parsing.model_libs.keras_input_lib import \
+            fix_input_layer_shape
+        shape = fix_input_layer_shape(shape)
+    fanout = np.zeros(shape[1:])
 
     for y_pre in range(fanout.shape[0 + ax]):
         y_post = [int((y_pre + py) / sy)]
@@ -1441,7 +1453,7 @@
     precision.
     """
 
-    import keras.backend as k
+    import tensorflow.keras.backend as k
     true_positives = k.sum(k.round(k.clip(y_true * y_pred, 0, 1)))
     predicted_positives = k.sum(k.round(k.clip(y_pred, 0, 1)))
     return true_positives / (predicted_positives + k.epsilon())
Index: mnt/2646BAF446BAC3B9/Repositories/inrc/nxsdk-apps/nxsdk_modules/snntoolbox/nx_backend.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- mnt/2646BAF446BAC3B9/Repositories/inrc/nxsdk-apps/nxsdk_modules/snntoolbox/nx_backend.py	(revision 1a1081016881fecfaf173bf9c8a79db9b899ecb1)
+++ mnt/2646BAF446BAC3B9/Repositories/inrc/nxsdk-apps/nxsdk_modules/snntoolbox/nx_backend.py	(date 1583415254931)
@@ -23,7 +23,7 @@
 import tempfile
 
 import numpy as np
-import keras
+import tensorflow.keras as keras
 
 import nxsdk_modules.dnn.src.dnn_layers as nxtf
 from nxsdk.graph.nxboard import N2Board
@@ -259,7 +259,7 @@
 
         if self.do_probe_spikes:
             compartment_kwargs['probeSpikes'] = True
-        input_layer = nxtf.NxInputLayer(batch_input_shape=input_shape,
+        input_layer = nxtf.NxInputLayer(input_shape[1:], input_shape[0],
                                         **layer_kwargs, **compartment_kwargs)
 
         maxNumCompartments = self.config.getint(
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/brian2_target_sim.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/brian2_target_sim.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/brian2_target_sim.py	(date 1583348223646)
@@ -265,7 +265,7 @@
                 np.savez(filepath, self.connections[i].w)
 
     def load(self, path, filename):
-        import keras
+        from tensorflow.keras.models import load_model
         from snntoolbox.parsing.utils import get_type
         from snntoolbox.simulation.utils import get_ann_ops
 
@@ -274,7 +274,7 @@
                      if os.path.isfile(os.path.join(dirpath, f))]
         print("Loading spiking model...")
 
-        self.parsed_model = keras.models.load_model(
+        self.parsed_model = load_model(
             os.path.join(self.config.get('paths', 'path_wd'),
                          self.config.get('paths',
                                          'filename_parsed_model') + '.h5'))
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/conversion/utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/conversion/utils.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/conversion/utils.py	(date 1583348222958)
@@ -17,7 +17,7 @@
 
 import os
 
-import keras
+from tensorflow.keras.models import Model
 import numpy as np
 from future import standard_library
 
@@ -345,7 +345,7 @@
     if len(x) % batch_size != 0:
         x = x[: -(len(x) % batch_size)]
 
-    return keras.models.Model(layer_in, layer_out).predict(x, batch_size)
+    return Model(layer_in, layer_out).predict(x, batch_size)
 
 
 def get_activations_batch(ann, x_batch):
@@ -384,8 +384,7 @@
                                         'Concatenate', 'ZeroPadding2D',
                                         'Reshape']:
             continue
-        activations = keras.models.Model(
-            ann.input, layer.output).predict_on_batch(x_batch)
+        activations = Model(ann.input, layer.output).predict_on_batch(x_batch)
         activations_batch.append((activations, layer.name))
     return activations_batch
 
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/utils.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/utils.py	(date 1583363939501)
@@ -19,7 +19,7 @@
 from snntoolbox.bin.utils import get_log_keys, get_plot_keys
 from snntoolbox.parsing.utils import get_type
 from snntoolbox.utils.utils import echo
-import keras
+import tensorflow.keras as keras
 
 
 class AbstractSNN:
@@ -422,7 +422,9 @@
                                                               'top_k'))
 
         # Get batch input shape
-        batch_shape = list(parsed_model.layers[0].batch_input_shape)
+        from snntoolbox.parsing.model_libs.keras_input_lib import \
+            fix_input_layer_shape
+        batch_shape = list(fix_input_layer_shape(parsed_model.layers[0].input_shape))
         batch_shape[0] = self.batch_size
         if self.config.get('conversion', 'spike_code') == 'ttfs_dyn_thresh':
             batch_shape[0] *= 2
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/backends/inisim/ttfs_dyn_thresh.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/backends/inisim/ttfs_dyn_thresh.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/backends/inisim/ttfs_dyn_thresh.py	(date 1583348222894)
@@ -22,9 +22,9 @@
 import numpy as np
 from future import standard_library
 import tensorflow as tf
-from keras import backend as k
-from keras.layers import Dense, Flatten, AveragePooling2D, MaxPooling2D, Conv2D
-from keras.layers import Layer, Concatenate
+import tensorflow.keras.backend as k
+from tensorflow.keras.layers import Dense, Flatten, AveragePooling2D, \
+    MaxPooling2D, Conv2D, Layer, Concatenate
 
 standard_library.install_aliases()
 
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/bin/utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/bin/utils.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/bin/utils.py	(date 1583344306932)
@@ -295,7 +295,7 @@
     os.environ['KERAS_BACKEND'] = keras_backend
     # The keras import has to happen after setting the backend environment
     # variable!
-    import keras.backend as k
+    import tensorflow.keras.backend as k
     assert k.backend() == keras_backend, \
         "Keras backend set to {} in snntoolbox config file, but has already " \
         "been set to {} by a previous keras import. Set backend " \
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/backends/inisim/ttfs.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/backends/inisim/ttfs.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/backends/inisim/ttfs.py	(date 1583348223546)
@@ -19,9 +19,9 @@
 import numpy as np
 from future import standard_library
 import tensorflow as tf
-from keras import backend as k
-from keras.layers import Dense, Flatten, AveragePooling2D, MaxPooling2D, Conv2D
-from keras.layers import Layer, Concatenate
+import tensorflow.keras.backend as k
+from tensorflow.keras.layers import Dense, Flatten, AveragePooling2D, \
+    MaxPooling2D, Conv2D, Layer, Concatenate
 
 standard_library.install_aliases()
 
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/utils/utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/utils/utils.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/utils/utils.py	(date 1583344203333)
@@ -6,7 +6,7 @@
 import os
 import sys
 
-import keras
+import tensorflow.keras as keras
 import numpy as np
 
 
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/backends/inisim/temporal_mean_rate_tensorflow.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/backends/inisim/temporal_mean_rate_tensorflow.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/backends/inisim/temporal_mean_rate_tensorflow.py	(date 1583348223694)
@@ -18,10 +18,10 @@
 import numpy as np
 from future import standard_library
 import tensorflow as tf
-from keras import backend as k
-from keras.layers import Dense, Flatten, AveragePooling2D, MaxPooling2D, \
-    Conv2D, DepthwiseConv2D, ZeroPadding2D, Reshape
-from keras.layers import Layer, Concatenate
+import tensorflow.keras.backend as k
+from tensorflow.keras.layers import Dense, Flatten, AveragePooling2D, \
+    MaxPooling2D, Conv2D, DepthwiseConv2D, ZeroPadding2D, Reshape, Layer, \
+    Concatenate
 
 from snntoolbox.parsing.utils import get_inbound_layers
 
Index: mnt/2646BAF446BAC3B9/Repositories/inrc/nxsdk-apps/nxsdk_modules/dnn/src/dnn_layers.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- mnt/2646BAF446BAC3B9/Repositories/inrc/nxsdk-apps/nxsdk_modules/dnn/src/dnn_layers.py	(revision 1a1081016881fecfaf173bf9c8a79db9b899ecb1)
+++ mnt/2646BAF446BAC3B9/Repositories/inrc/nxsdk-apps/nxsdk_modules/dnn/src/dnn_layers.py	(date 1583362782504)
@@ -28,10 +28,9 @@
 from typing import TYPE_CHECKING
 
 import numpy as np
-from keras.engine import InputLayer
-from keras.layers import Conv2D, DepthwiseConv2D, Dense, AveragePooling2D, \
-    Flatten, Conv1D, ZeroPadding2D, Reshape
-from keras.models import Model, load_model
+from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, Dense, AveragePooling2D, \
+    Flatten, Conv1D, ZeroPadding2D, Reshape, InputLayer
+from tensorflow.keras.models import Model, load_model
 from scipy.sparse import lil_matrix, load_npz, save_npz
 
 # Import plotting modules first to ensure plt backend is set correctly.
@@ -75,6 +74,16 @@
 CxAddr = collections.namedtuple('CxAddr', ['chipId', 'coreId', 'cxId'])
 
 
+def fix_input_layer_shape(shape):
+    """
+    tf.keras.models.load_model function introduced a bug that wraps the input
+    tensors and shapes in a single-entry list, i.e.
+    output_shape == [(None, 1, 28, 28)]. Thus we have to apply [0] here.
+    """
+
+    return shape[0]
+
+
 def removeNxKwargs(kwargs):
     """Remove keyword arguments not understood by Keras layer constructors.
 
@@ -305,7 +314,10 @@
     # is doubled.
     signedInput = False
     if len(self._inbound_nodes[:1]):
-        layer = self._inbound_nodes[0].inbound_layers[0]
+        layer = self._inbound_nodes[0].inbound_layers
+        # layer may be wrapped in a list of lenght 1:
+        if isinstance(layer, (list, tuple)):
+            layer = layer[0]
         if hasattr(layer, 'signed'):
             if layer.signed:
                 signedInput = True
@@ -1231,7 +1243,7 @@
     def build(self, input_shape):
         Conv2D.build(self, input_shape)
 
-        self._padding = _getPadding(input_shape[1:], self.padding,
+        self._padding = _getPadding(input_shape.as_list()[1:], self.padding,
                                     self.kernel_size, self.strides,
                                     self.dilation_rate)
 
@@ -1240,7 +1252,10 @@
         # When using signed spikes the number of channels in the input
         # is doubled.
         if len(self._inbound_nodes[:1]):
-            layer = self._inbound_nodes[0].inbound_layers[0]
+            layer = self._inbound_nodes[0].inbound_layers
+            # layer may be wrapped in a list of lenght 1:
+            if isinstance(layer, (list, tuple)):
+                layer = layer[0]
             if hasattr(layer, 'signed'):
                 if layer.signed:
                     inputShape = inputShape[:-1] + (2 * inputShape[-1],)
@@ -1380,7 +1395,7 @@
     def build(self, input_shape):
         Conv1D.build(self, input_shape)
 
-        self._input_shape3D = (input_shape[1], 1, input_shape[2])
+        self._input_shape3D = (int(input_shape[1]), 1, int(input_shape[2]))
         self._kernel_shape2D = (self.kernel_size[0], 1)
         self._strides2D = (self.strides[0], 1)
         self._dilation_rate2D = (self.dilation_rate[0], 1)
@@ -1491,8 +1506,8 @@
 
         DepthwiseConv2D.__init__(self, kernel_size, strides, padding, **kwargs)
 
-        if self.dilation_rate != (1, 1):
-            raise NotImplementedError
+        # if self.dilation_rate != (1, 1):
+        #     raise NotImplementedError
 
         # Padding tuple
         self._padding = None
@@ -1508,7 +1523,7 @@
     def build(self, input_shape):
         DepthwiseConv2D.build(self, input_shape)
 
-        self._padding = _getPadding(input_shape[1:], self.padding,
+        self._padding = _getPadding(input_shape.as_list()[1:], self.padding,
                                     self.kernel_size, self.strides,
                                     self.dilation_rate)
 
@@ -1617,13 +1632,14 @@
         return config
 
     def build(self, input_shape):
-        self._padding = _getPadding(input_shape[1:], self.padding,
+        input_shape_list = input_shape.as_list()
+        self._padding = _getPadding(input_shape_list[1:], self.padding,
                                     self.pool_size, self.strides, (1, 1))
 
-        output_shape = self.compute_output_shape(input_shape)
+        output_shape = self.compute_output_shape(input_shape_list)
 
         # Add weights and biases.
-        inChannels = input_shape[-1]
+        inChannels = input_shape_list[-1]
         outChannels = output_shape[-1]
         weightShape = self.pool_size + (inChannels, outChannels)
         self.add_weight('W', weightShape, initializer='ones', trainable=False)
@@ -1788,7 +1804,10 @@
         weights, biases = self.get_weights()
 
         if len(self._inbound_nodes):
-            prevLayer = self._inbound_nodes[0].inbound_layers[0]
+            prevLayer = self._inbound_nodes[0].inbound_layers
+            # prevLayer may be wrapped in a list of lenght 1:
+            if isinstance(prevLayer, (list, tuple)):
+                prevLayer = prevLayer[0]
             if 'Flatten' in prevLayer.__class__.__name__:
                 shape = prevLayer.input_shape[1:]
                 idxs = np.arange(int(np.prod(shape)))
@@ -2027,9 +2046,8 @@
 class NxInputLayer(NxLayer, InputLayer):
     """Input layer for Loihi DNNs."""
 
-    def __init__(self, input_shape=None, batch_size=None,
-                 batch_input_shape=None, biasExp=None, vThMant=None,
-                 visualizePartitions=None, logger=None,
+    def __init__(self, input_shape=None, batch_size=None, biasExp=None,
+                 vThMant=None, visualizePartitions=None, logger=None,
                  signed=False, **kwargs):
 
         NxLayer.__init__(self, biasExp=biasExp, vThMant=vThMant,
@@ -2041,8 +2059,7 @@
 
         kwargs = removeNxKwargs(kwargs)
 
-        InputLayer.__init__(self, input_shape, batch_size, batch_input_shape,
-                            **kwargs)
+        InputLayer.__init__(self, input_shape, batch_size, **kwargs)
 
     def get_config(self):
         config = {'signed': self._signed}
@@ -2063,7 +2080,7 @@
             particular array of candidates.
         :rtype: dict
         """
-        outputShape = self.output_shape[1:]
+        outputShape = fix_input_layer_shape(self.output_shape)[1:]
 
         # When using signed spikes the number of channels in the output
         # is doubled.
@@ -2086,7 +2103,7 @@
         """
 
         # Compute shape for signed input.
-        outputShape = self.output_shape[1:]
+        outputShape = fix_input_layer_shape(self.output_shape)[1:]
 
         # When using signed spikes the number of channels in the output
         # is doubled.
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/backends/inisim/temporal_pattern.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/backends/inisim/temporal_pattern.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/backends/inisim/temporal_pattern.py	(date 1583348223342)
@@ -20,10 +20,10 @@
 import numpy as np
 from future import standard_library
 import tensorflow as tf
-from keras import backend as k
-from keras.layers import Dense, Flatten, AveragePooling2D, MaxPooling2D, Conv2D
-from keras.layers import Layer, Concatenate
-from keras.activations import softmax, relu
+import tensorflow.keras.backend as k
+from tensorflow.keras.layers import Dense, Flatten, AveragePooling2D, \
+    MaxPooling2D, Conv2D, Layer, Concatenate
+from tensorflow.keras.activations import softmax, relu
 
 standard_library.install_aliases()
 
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/backends/inisim/ttfs_corrective.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/backends/inisim/ttfs_corrective.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/backends/inisim/ttfs_corrective.py	(date 1583348223494)
@@ -22,9 +22,9 @@
 import numpy as np
 from future import standard_library
 import tensorflow as tf
-from keras import backend as k
-from keras.layers import Dense, Flatten, AveragePooling2D, MaxPooling2D, Conv2D
-from keras.layers import Layer, Concatenate
+import tensorflow.keras.backend as k
+from tensorflow.keras.layers import Dense, Flatten, AveragePooling2D, \
+    MaxPooling2D, Conv2D, Layer, Concatenate
 
 standard_library.install_aliases()
 
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/examples/mnist_keras_INI.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/examples/mnist_keras_INI.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/examples/mnist_keras_INI.py	(date 1583432531836)
@@ -11,13 +11,12 @@
 import time
 import numpy as np
 
-import keras
-from keras import Input, Model
-from keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Dropout, \
-    Concatenate
-from keras.layers import BatchNormalization, Activation
-from keras.datasets import mnist
-from keras.utils import np_utils
+import tensorflow.keras as keras
+from tensorflow.keras import Input, Model
+from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, \
+    Dropout, Concatenate, BatchNormalization, Activation
+from tensorflow.keras.datasets import mnist
+from tensorflow.keras.utils import to_categorical
 
 from snntoolbox.bin.run import main
 from snntoolbox.utils.utils import import_configparser
@@ -48,8 +47,8 @@
 x_test = np.expand_dims(x_test, axis)
 
 # One-hot encode target vectors.
-y_train = np_utils.to_categorical(y_train, 10)
-y_test = np_utils.to_categorical(y_test, 10)
+y_train = to_categorical(y_train, 10)
+y_test = to_categorical(y_test, 10)
 
 # Save dataset so SNN toolbox can find it.
 np.savez_compressed(os.path.join(path_wd, 'x_test'), x_test)
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/parsing/model_libs/lasagne_input_lib.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/parsing/model_libs/lasagne_input_lib.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/parsing/model_libs/lasagne_input_lib.py	(date 1583348223114)
@@ -98,7 +98,7 @@
     def parse_convolution(self, layer, attributes):
         weights = layer.W.get_value()
         weights = np.transpose(weights, (2, 3, 1, 0))
-        import keras
+        import tensorflow.keras as keras
         if keras.backend.backend() != 'theano':  # Assumes lasagne uses theano.
             weights = keras.utils.conv_utils.convert_kernel(weights)
         bias = layer.b.get_value()
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/parsing/model_libs/keras_input_lib.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/parsing/model_libs/keras_input_lib.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/parsing/model_libs/keras_input_lib.py	(date 1583362782658)
@@ -5,7 +5,7 @@
 """
 
 import numpy as np
-import keras.backend as k
+import tensorflow.keras.backend as k
 from snntoolbox.parsing.utils import AbstractModelParser
 
 
@@ -27,6 +27,9 @@
         beta = np.zeros_like(mean) if layer.beta is None else \
             k.get_value(layer.beta)
         axis = layer.axis
+        if isinstance(axis, (list, tuple)):
+            assert len(axis) == 1, "Multiple BatchNorm axes not understood."
+            axis = axis[0]
 
         return [mean, var_eps_sqrt_inv, gamma, beta, axis]
 
@@ -49,7 +52,7 @@
         return attributes
 
     def get_input_shape(self):
-        return tuple(self.get_layer_iterable()[0].batch_input_shape[1:])
+        return fix_input_layer_shape(self.get_layer_iterable()[0].input_shape)[1:]
 
     def get_output_shape(self, layer):
         return layer.output_shape
@@ -134,7 +137,7 @@
     """
 
     import os
-    from keras import models, metrics
+    from tensorflow.keras import models, metrics
 
     filepath = str(os.path.join(path, filename))
 
@@ -215,3 +218,13 @@
     print("Top-5 accuracy: {:.2%}\n".format(score[2]))
 
     return score[1]
+
+
+def fix_input_layer_shape(shape):
+    """
+    tf.keras.models.load_model function introduced a bug that wraps the input
+    tensors and shapes in a single-entry list, i.e.
+    output_shape == [(None, 1, 28, 28)]. Thus we have to apply [0] here.
+    """
+
+    return shape[0]
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/spiNNaker_target_sim.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/spiNNaker_target_sim.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/spiNNaker_target_sim.py	(date 1583348223062)
@@ -13,7 +13,7 @@
 import warnings
 
 import numpy as np
-import keras
+import tensorflow.keras as keras
 from snntoolbox.utils.utils import confirm_overwrite
 from snntoolbox.simulation.target_simulators.pyNN_target_sim import SNN as PYSNN
 
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/datasets/utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/datasets/utils.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/datasets/utils.py	(date 1583348223162)
@@ -93,7 +93,7 @@
 
     # ________________________________ jpg ___________________________________#
     elif config.get('input', 'dataset_format') in {'jpg', 'png'}:
-        from keras.preprocessing.image import ImageDataGenerator
+        from tensorflow.keras.preprocessing.image import ImageDataGenerator
         print("Loading data set from ImageDataGenerator, using images in "
               "{}.\n".format(dataset_path))
         # Transform str to dict
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/INI_ttfs_target_sim.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/INI_ttfs_target_sim.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/INI_ttfs_target_sim.py	(date 1583348223394)
@@ -8,7 +8,7 @@
 from __future__ import print_function, unicode_literals
 
 import sys
-import keras
+import tensorflow.keras as keras
 import numpy as np
 from future import standard_library
 
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/INI_ttfs_dyn_thresh_target_sim.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/INI_ttfs_dyn_thresh_target_sim.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/INI_ttfs_dyn_thresh_target_sim.py	(date 1583348223442)
@@ -8,7 +8,7 @@
 from __future__ import print_function, unicode_literals
 
 import sys
-import keras
+import tensorflow.keras as keras
 import numpy as np
 from future import standard_library
 
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/INI_temporal_pattern_target_sim.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/INI_temporal_pattern_target_sim.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/INI_temporal_pattern_target_sim.py	(date 1583348223590)
@@ -9,7 +9,7 @@
 
 import re
 
-import keras
+import tensorflow.keras as keras
 import numpy as np
 from future import standard_library
 
Index: home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/INI_temporal_mean_rate_target_sim.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/INI_temporal_mean_rate_target_sim.py	(revision c792a4645eacdc2f530b99899b59744922cfc5cf)
+++ home/rbodo/PycharmProjects/snn_toolbox_loihi/snntoolbox/simulation/target_simulators/INI_temporal_mean_rate_target_sim.py	(date 1583429753874)
@@ -11,7 +11,7 @@
 import re
 import sys
 
-import keras
+import tensorflow.keras as keras
 import numpy as np
 from future import standard_library
 
@@ -64,8 +64,10 @@
         from snntoolbox.parsing.utils import get_type
         spike_layer_name = getattr(self.sim, 'Spike' + get_type(layer))
         # noinspection PyProtectedMember
-        inbound = [self._spiking_layers[inb.name] for inb in
-                   layer._inbound_nodes[0].inbound_layers]
+        inbound = layer._inbound_nodes[0].inbound_layers
+        if not isinstance(inbound, (list, tuple)):
+            inbound = [inbound]
+        inbound = [self._spiking_layers[inb.name] for inb in inbound]
         if len(inbound) == 1:
             inbound = inbound[0]
         layer_kwargs = layer.get_config()
